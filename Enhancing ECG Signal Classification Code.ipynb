{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-average",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T15:16:09.888306Z",
     "iopub.status.busy": "2024-05-29T15:16:09.887909Z",
     "iopub.status.idle": "2024-05-29T15:17:16.860392Z",
     "shell.execute_reply": "2024-05-29T15:17:16.859540Z",
     "shell.execute_reply.started": "2024-05-29T15:16:09.888271Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pywt\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display plots inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 6)\n",
    "plt.rcParams['lines.linewidth'] = 1\n",
    "plt.rcParams['lines.color'] = 'b'\n",
    "plt.rcParams['axes.grid'] = True \n",
    "\n",
    "# Function for denoising ECG signals using wavelet transform\n",
    "def denoise(data): \n",
    "    w = pywt.Wavelet('sym4')\n",
    "    maxlev = pywt.dwt_max_level(len(data), w.dec_len)\n",
    "    threshold = 0.04  # Threshold for filtering\n",
    "\n",
    "    coeffs = pywt.wavedec(data, 'sym4', level=maxlev)\n",
    "    for i in range(1, len(coeffs)):\n",
    "        coeffs[i] = pywt.threshold(coeffs[i], threshold * max(coeffs[i]))\n",
    "        \n",
    "    datarec = pywt.waverec(coeffs, 'sym4')\n",
    "    \n",
    "    return datarec\n",
    "\n",
    "# Function to add different types of noise to ECG signals\n",
    "def add_noise(data, noise_type=\"gaussian\", noise_level=0.01):\n",
    "    if noise_type == \"gaussian\":\n",
    "        noise = np.random.normal(0, noise_level, data.shape)\n",
    "    elif noise_type == \"salt_pepper\":\n",
    "        noise = np.random.choice([0, 1], size=data.shape, p=[1 - noise_level, noise_level])\n",
    "        noise = noise * (np.random.choice([-1, 1], size=data.shape))\n",
    "    elif noise_type == \"speckle\":\n",
    "        noise = data + data * np.random.normal(0, noise_level, data.shape)\n",
    "    elif noise_type == \"uniform\":\n",
    "        noise = np.random.uniform(-noise_level, noise_level, data.shape)\n",
    "    elif noise_type == \"exponential\":\n",
    "        noise = np.random.exponential(noise_level, data.shape)\n",
    "    else:\n",
    "        noise = np.zeros_like(data)\n",
    "    return data + noise\n",
    "\n",
    "# Path to MIT-BIH Arrhythmia Database\n",
    "path = '/kaggle/input/mitbit-arrhythmia-database/mitbih_database/'\n",
    "window_size = 1000  # Define the window size for segmenting ECG signals\n",
    "\n",
    "# Lists to store features (X)\n",
    "X = []\n",
    "\n",
    "# Read files from the dataset directory\n",
    "filenames = next(os.walk(path))[2]\n",
    "filenames.sort()\n",
    "\n",
    "# Segregate filenames and annotations\n",
    "records = []\n",
    "annotations = []\n",
    "for f in filenames:\n",
    "    filename, file_extension = os.path.splitext(f)\n",
    "    if file_extension == '.csv':\n",
    "        records.append(path + filename + file_extension)\n",
    "    else:\n",
    "        annotations.append(path + filename + file_extension)\n",
    "\n",
    "# Load data from records\n",
    "for r in range(0, len(records)):\n",
    "    signals = []\n",
    "\n",
    "    with open(records[r], 'rt') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        row_index = -1\n",
    "        for row in spamreader:\n",
    "            if row_index >= 0:\n",
    "                signals.insert(row_index, int(row[1]))\n",
    "            row_index += 1\n",
    "\n",
    "    signals = stats.zscore(signals)\n",
    "    \n",
    "    # Add noise to the signals\n",
    "    noisy_signals = add_noise(signals, noise_type=\"gaussian\", noise_level=0.05)\n",
    "    \n",
    "    # Denoise the noisy signals\n",
    "    denoised_signals = denoise(noisy_signals)\n",
    "    \n",
    "    # Store original, noisy, and denoised signals for evaluation\n",
    "    X.append((signals, noisy_signals, denoised_signals))\n",
    "\n",
    "# Visualize noise addition and removal\n",
    "plt.figure(figsize=(15, 18))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(X[0][0][:3000])\n",
    "plt.title('Original Signal')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(X[0][1][:3000])\n",
    "plt.title('Noisy Signal')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(X[0][2][:3000])\n",
    "plt.title('Denoised Signal')\n",
    "\n",
    "# Visualize noise addition and removal\n",
    "plt.figure(figsize=(15, 18))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(X[0][0][:3000])\n",
    "plt.title('Original Signal')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(X[0][1][:3000])\n",
    "plt.title('Noisy Signal')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(X[0][2][:3000])\n",
    "plt.title('Denoised Signal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Add the new visualization code here\n",
    "# Visualize comparison of original, noisy, and denoised signals in a single plot\n",
    "plt.figure(figsize=(15, 6))  # Change the figure size as needed\n",
    "\n",
    "plt.plot(X[0][0][:3000], label='Original Signal', color='blue')\n",
    "plt.plot(X[0][1][:3000], label='Noisy Signal', color='red', alpha=0.7)\n",
    "plt.plot(X[0][2][:3000], label='Denoised Signal', color='green', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.title('Comparison of Original, Noisy, and Denoised Signals')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the denoising performance\n",
    "original_signals = np.array([x[0] for x in X])\n",
    "noisy_signals = np.array([x[1] for x in X])\n",
    "denoised_signals = np.array([x[2] for x in X])\n",
    "\n",
    "mse_noisy = mean_squared_error(original_signals.flatten(), noisy_signals.flatten())\n",
    "mse_denoised = mean_squared_error(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "r2_noisy = r2_score(original_signals.flatten(), noisy_signals.flatten())\n",
    "r2_denoised = r2_score(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "mae_noisy = mean_absolute_error(original_signals.flatten(), noisy_signals.flatten())\n",
    "mae_denoised = mean_absolute_error(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "corr_noisy, _ = pearsonr(original_signals.flatten(), noisy_signals.flatten())\n",
    "corr_denoised, _ = pearsonr(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "print(f'MSE (Noisy Signals): {mse_noisy}')\n",
    "print(f'MSE (Denoised Signals): {mse_denoised}')\n",
    "print(f'R^2 (Noisy Signals): {r2_noisy}')\n",
    "print(f'R^2 (Denoised Signals): {r2_denoised}')\n",
    "print(f'MAE (Noisy Signals): {mae_noisy}')\n",
    "print(f'MAE (Denoised Signals): {mae_denoised}')\n",
    "print(f'Correlation (Noisy Signals): {corr_noisy}')\n",
    "print(f'Correlation (Denoised Signals): {corr_denoised}')\n",
    "\n",
    "# Create DataFrame for evaluation metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['MSE', 'R2', 'MAE', 'Correlation'],\n",
    "    'Noisy': [mse_noisy, r2_noisy, mae_noisy, corr_noisy],\n",
    "    'Denoised': [mse_denoised, r2_denoised, mae_denoised, corr_denoised]\n",
    "})\n",
    "\n",
    "# Plot comparison of evaluation metrics\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "for i, (idx, row) in enumerate(metrics_df.iterrows()):\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    ax.bar(['Noisy', 'Denoised'], row[['Noisy', 'Denoised']], color=['red', 'green'])\n",
    "    ax.set_title(row['Metric'])\n",
    "    ax.set_ylabel(row['Metric'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot dataset distribution\n",
    "signal_lengths = [len(x[0]) for x in X]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(signal_lengths, bins=50, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Signal Lengths in the Dataset')\n",
    "plt.xlabel('Signal Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-concord",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T15:36:38.864781Z",
     "iopub.status.busy": "2024-05-29T15:36:38.864364Z",
     "iopub.status.idle": "2024-05-29T15:37:45.493575Z",
     "shell.execute_reply": "2024-05-29T15:37:45.492691Z",
     "shell.execute_reply.started": "2024-05-29T15:36:38.864719Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pywt\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display plots inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 6)\n",
    "plt.rcParams['lines.linewidth'] = 1\n",
    "plt.rcParams['lines.color'] = 'b'\n",
    "plt.rcParams['axes.grid'] = True \n",
    "\n",
    "# Function for denoising ECG signals using wavelet transform\n",
    "def denoise(data): \n",
    "    w = pywt.Wavelet('sym4')\n",
    "    maxlev = pywt.dwt_max_level(len(data), w.dec_len)\n",
    "    threshold = 0.04  # Threshold for filtering\n",
    "\n",
    "    coeffs = pywt.wavedec(data, 'sym4', level=maxlev)\n",
    "    for i in range(1, len(coeffs)):\n",
    "        coeffs[i] = pywt.threshold(coeffs[i], threshold * max(coeffs[i]))\n",
    "        \n",
    "    datarec = pywt.waverec(coeffs, 'sym4')\n",
    "    \n",
    "    return datarec\n",
    "\n",
    "# Function to add different types of noise to ECG signals\n",
    "def add_noise(data, noise_type=\"gaussian\", noise_level=0.01):\n",
    "    if noise_type == \"gaussian\":\n",
    "        noise = np.random.normal(0, noise_level, data.shape)\n",
    "    elif noise_type == \"salt_pepper\":\n",
    "        noise = np.random.choice([0, 1], size=data.shape, p=[1 - noise_level, noise_level])\n",
    "        noise = noise * (np.random.choice([-1, 1], size=data.shape))\n",
    "    elif noise_type == \"speckle\":\n",
    "        noise = data + data * np.random.normal(0, noise_level, data.shape)\n",
    "    elif noise_type == \"uniform\":\n",
    "        noise = np.random.uniform(-noise_level, noise_level, data.shape)\n",
    "    elif noise_type == \"exponential\":\n",
    "        noise = np.random.exponential(noise_level, data.shape)\n",
    "    else:\n",
    "        noise = np.zeros_like(data)\n",
    "    return data + noise\n",
    "\n",
    "# Path to MIT-BIH Arrhythmia Database\n",
    "path = '/kaggle/input/mitbit-arrhythmia-database/mitbih_database/'\n",
    "window_size = 1000  # Define the window size for segmenting ECG signals\n",
    "\n",
    "# Lists to store features (X)\n",
    "X = []\n",
    "\n",
    "# Read files from the dataset directory\n",
    "filenames = next(os.walk(path))[2]\n",
    "filenames.sort()\n",
    "\n",
    "# Segregate filenames and annotations\n",
    "records = []\n",
    "annotations = []\n",
    "for f in filenames:\n",
    "    filename, file_extension = os.path.splitext(f)\n",
    "    if file_extension == '.csv':\n",
    "        records.append(path + filename + file_extension)\n",
    "    else:\n",
    "        annotations.append(path + filename + file_extension)\n",
    "\n",
    "# Load data from records\n",
    "for r in range(0, len(records)):\n",
    "    signals = []\n",
    "\n",
    "    with open(records[r], 'rt') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        row_index = -1\n",
    "        for row in spamreader:\n",
    "            if row_index >= 0:\n",
    "                signals.insert(row_index, int(row[1]))\n",
    "            row_index += 1\n",
    "\n",
    "    signals = stats.zscore(signals)\n",
    "    \n",
    "    # Add noise to the signals\n",
    "    noisy_signals = add_noise(signals, noise_type=\"gaussian\", noise_level=0.05)\n",
    "    \n",
    "    # Denoise the noisy signals\n",
    "    denoised_signals = denoise(noisy_signals)\n",
    "    \n",
    "    # Store original, noisy, and denoised signals for evaluation\n",
    "    X.append((signals, noisy_signals, denoised_signals))\n",
    "\n",
    "# Visualize noise addition and removal\n",
    "plt.figure(figsize=(15, 18))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(X[0][0][:3000])\n",
    "plt.title('Original Signal')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(X[0][1][:3000])\n",
    "plt.title('Noisy Signal')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(X[0][2][:3000])\n",
    "plt.title('Denoised Signal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize comparison of original, noisy, and denoised signals in a single plot\n",
    "plt.figure(figsize=(15, 6))  # Change the figure size as needed\n",
    "\n",
    "plt.plot(X[0][0][:3000], label='Original Signal', color='blue')\n",
    "plt.plot(X[0][1][:3000], label='Noisy Signal', color='red', alpha=0.7)\n",
    "plt.plot(X[0][2][:3000], label='Denoised Signal', color='green', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.title('Comparison of Original, Noisy, and Denoised Signals')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the denoising performance\n",
    "original_signals = np.array([x[0] for x in X])\n",
    "noisy_signals = np.array([x[1] for x in X])\n",
    "denoised_signals = np.array([x[2] for x in X])\n",
    "\n",
    "mse_noisy = mean_squared_error(original_signals.flatten(), noisy_signals.flatten())\n",
    "mse_denoised = mean_squared_error(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "r2_noisy = r2_score(original_signals.flatten(), noisy_signals.flatten())\n",
    "r2_denoised = r2_score(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "mae_noisy = mean_absolute_error(original_signals.flatten(), noisy_signals.flatten())\n",
    "mae_denoised = mean_absolute_error(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "corr_noisy, _ = pearsonr(original_signals.flatten(), noisy_signals.flatten())\n",
    "corr_denoised, _ = pearsonr(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "print(f'MSE (Noisy Signals): {mse_noisy}')\n",
    "print(f'MSE (Denoised Signals): {mse_denoised}')\n",
    "print(f'R^2 (Noisy Signals): {r2_noisy}')\n",
    "print(f'R^2 (Denoised Signals): {r2_denoised}')\n",
    "print(f'MAE (Noisy Signals): {mae_noisy}')\n",
    "print(f'MAE (Denoised Signals): {mae_denoised}')\n",
    "print(f'Correlation (Noisy Signals): {corr_noisy}')\n",
    "print(f'Correlation (Denoised Signals): {corr_denoised}')\n",
    "\n",
    "# Create DataFrame for evaluation metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['MSE', 'R2', 'MAE', 'Correlation'],\n",
    "    'Noisy': [mse_noisy, r2_noisy, mae_noisy, corr_noisy],\n",
    "    'Denoised': [mse_denoised, r2_denoised, mae_denoised, corr_denoised]\n",
    "})\n",
    "\n",
    "# Plot comparison of evaluation metrics\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "for i, (idx, row) in enumerate(metrics_df.iterrows()):\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    ax.bar(['Noisy', 'Denoised'], row[['Noisy', 'Denoised']], color=['red', 'green'])\n",
    "    ax.set_title(row['Metric'])\n",
    "    ax.set_ylabel(row['Metric'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot dataset distribution\n",
    "signal_lengths = [len(x[0]) for x in X]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(signal_lengths, bins=50, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Signal Lengths in the Dataset')\n",
    "plt.xlabel('Signal Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-problem",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T15:41:05.438360Z",
     "iopub.status.busy": "2024-05-29T15:41:05.437998Z",
     "iopub.status.idle": "2024-05-29T15:42:10.140173Z",
     "shell.execute_reply": "2024-05-29T15:42:10.139249Z",
     "shell.execute_reply.started": "2024-05-29T15:41:05.438330Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pywt\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display plots inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 6)\n",
    "plt.rcParams['lines.linewidth'] = 1\n",
    "plt.rcParams['lines.color'] = 'b'\n",
    "plt.rcParams['axes.grid'] = True \n",
    "\n",
    "# Function for denoising ECG signals using wavelet transform\n",
    "def denoise(data): \n",
    "    w = pywt.Wavelet('sym4')\n",
    "    maxlev = pywt.dwt_max_level(len(data), w.dec_len)\n",
    "    threshold = 0.04  # Threshold for filtering\n",
    "\n",
    "    coeffs = pywt.wavedec(data, 'sym4', level=maxlev)\n",
    "    for i in range(1, len(coeffs)):\n",
    "        coeffs[i] = pywt.threshold(coeffs[i], threshold * max(coeffs[i]))\n",
    "        \n",
    "    datarec = pywt.waverec(coeffs, 'sym4')\n",
    "    \n",
    "    return datarec\n",
    "\n",
    "# Function to add different types of noise to ECG signals\n",
    "def add_noise(data, noise_type=\"gaussian\", noise_level=0.01):\n",
    "    if noise_type == \"gaussian\":\n",
    "        noise = np.random.normal(0, noise_level, data.shape)\n",
    "    elif noise_type == \"salt_pepper\":\n",
    "        noise = np.random.choice([0, 1], size=data.shape, p=[1 - noise_level, noise_level])\n",
    "        noise = noise * (np.random.choice([-1, 1], size=data.shape))\n",
    "    elif noise_type == \"speckle\":\n",
    "        noise = data + data * np.random.normal(0, noise_level, data.shape)\n",
    "    elif noise_type == \"uniform\":\n",
    "        noise = np.random.uniform(-noise_level, noise_level, data.shape)\n",
    "    elif noise_type == \"exponential\":\n",
    "        noise = np.random.exponential(noise_level, data.shape)\n",
    "    else:\n",
    "        noise = np.zeros_like(data)\n",
    "    return data + noise\n",
    "\n",
    "# Path to MIT-BIH Arrhythmia Database\n",
    "path = '/kaggle/input/mitbit-arrhythmia-database/mitbih_database/'\n",
    "window_size = 1000  # Define the window size for segmenting ECG signals\n",
    "\n",
    "# Lists to store features (X)\n",
    "X = []\n",
    "\n",
    "# Read files from the dataset directory\n",
    "filenames = next(os.walk(path))[2]\n",
    "filenames.sort()\n",
    "\n",
    "# Segregate filenames and annotations\n",
    "records = []\n",
    "annotations = []\n",
    "for f in filenames:\n",
    "    filename, file_extension = os.path.splitext(f)\n",
    "    if file_extension == '.csv':\n",
    "        records.append(path + filename + file_extension)\n",
    "    else:\n",
    "        annotations.append(path + filename + file_extension)\n",
    "\n",
    "# Load data from records\n",
    "for r in range(0, len(records)):\n",
    "    signals = []\n",
    "\n",
    "    with open(records[r], 'rt') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        row_index = -1\n",
    "        for row in spamreader:\n",
    "            if row_index >= 0:\n",
    "                signals.insert(row_index, int(row[1]))\n",
    "            row_index += 1\n",
    "\n",
    "    signals = stats.zscore(signals)\n",
    "    \n",
    "    # Add noise to the signals\n",
    "    noisy_signals = add_noise(signals, noise_type=\"gaussian\", noise_level=0.05)\n",
    "    \n",
    "    # Denoise the noisy signals\n",
    "    denoised_signals = denoise(noisy_signals)\n",
    "    \n",
    "    # Store original, noisy, and denoised signals for evaluation\n",
    "    X.append((signals, noisy_signals, denoised_signals))\n",
    "\n",
    "# Visualize noise addition and removal\n",
    "plt.figure(figsize=(15, 18))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(X[0][0][:3000])\n",
    "plt.title('Original Signal')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(X[0][1][:3000])\n",
    "plt.title('Noisy Signal')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(X[0][2][:3000])\n",
    "plt.title('Denoised Signal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the denoising performance\n",
    "original_signals = np.array([x[0] for x in X])\n",
    "noisy_signals = np.array([x[1] for x in X])\n",
    "denoised_signals = np.array([x[2] for x in X])\n",
    "\n",
    "mse_noisy = mean_squared_error(original_signals.flatten(), noisy_signals.flatten())\n",
    "mse_denoised = mean_squared_error(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "r2_noisy = r2_score(original_signals.flatten(), noisy_signals.flatten())\n",
    "r2_denoised = r2_score(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "mae_noisy = mean_absolute_error(original_signals.flatten(), noisy_signals.flatten())\n",
    "mae_denoised = mean_absolute_error(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "corr_noisy, _ = pearsonr(original_signals.flatten(), noisy_signals.flatten())\n",
    "corr_denoised, _ = pearsonr(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "print(f'MSE (Noisy Signals): {mse_noisy}')\n",
    "print(f'MSE (Denoised Signals): {mse_denoised}')\n",
    "print(f'R^2 (Noisy Signals): {r2_noisy}')\n",
    "print(f'R^2 (Denoised Signals): {r2_denoised}')\n",
    "print(f'MAE (Noisy Signals): {mae_noisy}')\n",
    "print(f'MAE (Denoised Signals): {mae_denoised}')\n",
    "print(f'Correlation (Noisy Signals): {corr_noisy}')\n",
    "print(f'Correlation (Denoised Signals): {corr_denoised}')\n",
    "\n",
    "# Create DataFrame for evaluation metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['MSE', 'R2', 'MAE', 'Correlation'],\n",
    "    'Noisy': [mse_noisy, r2_noisy, mae_noisy, corr_noisy],\n",
    "    'Denoised': [mse_denoised, r2_denoised, mae_denoised, corr_denoised]\n",
    "})\n",
    "\n",
    "# Plot comparison of evaluation metrics\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "for i, (idx, row) in enumerate(metrics_df.iterrows()):\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    ax.bar(['Noisy', 'Denoised'], row[['Noisy', 'Denoised']], color=['red', 'green'])\n",
    "    ax.set_title(row['Metric'])\n",
    "    ax.set_ylabel(row['Metric'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot dataset distribution\n",
    "signal_lengths = [len(x[0]) for x in X]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(signal_lengths, bins=50, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Signal Lengths in the Dataset')\n",
    "plt.xlabel('Signal Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Create a pie chart for the dataset distribution\n",
    "data_types = ['Original', 'Noisy', 'Denoised']\n",
    "data_counts = [len(X), len(X), len(X)]  # Assuming we have equal counts for each type for simplicity\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(data_counts, labels=data_types, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Distribution of Dataset by Data Type')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-spelling",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T15:51:22.679293Z",
     "iopub.status.busy": "2024-05-29T15:51:22.678932Z",
     "iopub.status.idle": "2024-05-29T15:52:27.599333Z",
     "shell.execute_reply": "2024-05-29T15:52:27.598530Z",
     "shell.execute_reply.started": "2024-05-29T15:51:22.679263Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pywt\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display plots inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 6)\n",
    "plt.rcParams['lines.linewidth'] = 1\n",
    "plt.rcParams['lines.color'] = 'b'\n",
    "plt.rcParams['axes.grid'] = True \n",
    "\n",
    "# Function for denoising ECG signals using wavelet transform\n",
    "def denoise(data): \n",
    "    w = pywt.Wavelet('sym4')\n",
    "    maxlev = pywt.dwt_max_level(len(data), w.dec_len)\n",
    "    threshold = 0.04  # Threshold for filtering\n",
    "\n",
    "    coeffs = pywt.wavedec(data, 'sym4', level=maxlev)\n",
    "    for i in range(1, len(coeffs)):\n",
    "        coeffs[i] = pywt.threshold(coeffs[i], threshold * max(coeffs[i]))\n",
    "        \n",
    "    datarec = pywt.waverec(coeffs, 'sym4')\n",
    "    \n",
    "    return datarec\n",
    "\n",
    "# Function to add different types of noise to ECG signals\n",
    "def add_noise(data, noise_type=\"gaussian\", noise_level=0.01):\n",
    "    if noise_type == \"gaussian\":\n",
    "        noise = np.random.normal(0, noise_level, data.shape)\n",
    "    elif noise_type == \"salt_pepper\":\n",
    "        noise = np.random.choice([0, 1], size=data.shape, p=[1 - noise_level, noise_level])\n",
    "        noise = noise * (np.random.choice([-1, 1], size=data.shape))\n",
    "    elif noise_type == \"speckle\":\n",
    "        noise = data + data * np.random.normal(0, noise_level, data.shape)\n",
    "    elif noise_type == \"uniform\":\n",
    "        noise = np.random.uniform(-noise_level, noise_level, data.shape)\n",
    "    elif noise_type == \"exponential\":\n",
    "        noise = np.random.exponential(noise_level, data.shape)\n",
    "    else:\n",
    "        noise = np.zeros_like(data)\n",
    "    return data + noise\n",
    "\n",
    "# Path to MIT-BIH Arrhythmia Database\n",
    "path = '/kaggle/input/mitbit-arrhythmia-database/mitbih_database/'\n",
    "window_size = 1000  # Define the window size for segmenting ECG signals\n",
    "\n",
    "# Lists to store features (X)\n",
    "X = []\n",
    "\n",
    "# Read files from the dataset directory\n",
    "filenames = next(os.walk(path))[2]\n",
    "filenames.sort()\n",
    "\n",
    "# Segregate filenames and annotations\n",
    "records = []\n",
    "annotations = []\n",
    "for f in filenames:\n",
    "    filename, file_extension = os.path.splitext(f)\n",
    "    if file_extension == '.csv':\n",
    "        records.append(path + filename + file_extension)\n",
    "    else:\n",
    "        annotations.append(path + filename + file_extension)\n",
    "\n",
    "# Load data from records\n",
    "for r in range(0, len(records)):\n",
    "    signals = []\n",
    "\n",
    "    with open(records[r], 'rt') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        row_index = -1\n",
    "        for row in spamreader:\n",
    "            if row_index >= 0:\n",
    "                signals.insert(row_index, int(row[1]))\n",
    "            row_index += 1\n",
    "\n",
    "    signals = stats.zscore(signals)\n",
    "    \n",
    "    # Add noise to the signals\n",
    "    noisy_signals = add_noise(signals, noise_type=\"gaussian\", noise_level=0.05)\n",
    "    \n",
    "    # Denoise the noisy signals\n",
    "    denoised_signals = denoise(noisy_signals)\n",
    "    \n",
    "    # Store original, noisy, and denoised signals for evaluation\n",
    "    X.append((signals, noisy_signals, denoised_signals))\n",
    "\n",
    "# Visualize noise addition and removal\n",
    "plt.figure(figsize=(15, 18))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(X[0][0][:3000])\n",
    "plt.title('Original Signal')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(X[0][1][:3000])\n",
    "plt.title('Noisy Signal')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(X[0][2][:3000])\n",
    "plt.title('Denoised Signal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the denoising performance\n",
    "original_signals = np.array([x[0] for x in X])\n",
    "noisy_signals = np.array([x[1] for x in X])\n",
    "denoised_signals = np.array([x[2] for x in X])\n",
    "\n",
    "mse_noisy = mean_squared_error(original_signals.flatten(), noisy_signals.flatten())\n",
    "mse_denoised = mean_squared_error(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "r2_noisy = r2_score(original_signals.flatten(), noisy_signals.flatten())\n",
    "r2_denoised = r2_score(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "mae_noisy = mean_absolute_error(original_signals.flatten(), noisy_signals.flatten())\n",
    "mae_denoised = mean_absolute_error(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "corr_noisy, _ = pearsonr(original_signals.flatten(), noisy_signals.flatten())\n",
    "corr_denoised, _ = pearsonr(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "print(f'MSE (Noisy Signals): {mse_noisy}')\n",
    "print(f'MSE (Denoised Signals): {mse_denoised}')\n",
    "print(f'R^2 (Noisy Signals): {r2_noisy}')\n",
    "print(f'R^2 (Denoised Signals): {r2_denoised}')\n",
    "print(f'MAE (Noisy Signals): {mae_noisy}')\n",
    "print(f'MAE (Denoised Signals): {mae_denoised}')\n",
    "print(f'Correlation (Noisy Signals): {corr_noisy}')\n",
    "print(f'Correlation (Denoised Signals): {corr_denoised}')\n",
    "\n",
    "# Create DataFrame for evaluation metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['MSE', 'R2', 'MAE', 'Correlation'],\n",
    "    'Noisy': [mse_noisy, r2_noisy, mae_noisy, corr_noisy],\n",
    "    'Denoised': [mse_denoised, r2_denoised, mae_denoised, corr_denoised]\n",
    "})\n",
    "\n",
    "# Plot comparison of evaluation metrics\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "for i, (idx, row) in enumerate(metrics_df.iterrows()):\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    ax.bar(['Noisy', 'Denoised'], row[['Noisy', 'Denoised']], color=['red', 'green'])\n",
    "    ax.set_title(row['Metric'])\n",
    "    ax.set_ylabel(row['Metric'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot dataset distribution\n",
    "signal_lengths = [len(x[0]) for x in X]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(signal_lengths, bins=50, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Signal Lengths in the Dataset')\n",
    "plt.xlabel('Signal Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Pie chart for dataset distribution\n",
    "labels = ['Records', 'Annotations']\n",
    "sizes = [len(records), len(annotations)]\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140, colors=['skyblue', 'lightgreen'])\n",
    "plt.title('Distribution of Data Types in the Dataset')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-fifteen",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T16:16:02.778830Z",
     "iopub.status.busy": "2024-05-29T16:16:02.778425Z",
     "iopub.status.idle": "2024-05-29T16:17:09.092641Z",
     "shell.execute_reply": "2024-05-29T16:17:09.091785Z",
     "shell.execute_reply.started": "2024-05-29T16:16:02.778794Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pywt\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display plots inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 6)\n",
    "plt.rcParams['lines.linewidth'] = 1\n",
    "plt.rcParams['lines.color'] = 'b'\n",
    "plt.rcParams['axes.grid'] = True \n",
    "\n",
    "# Function for denoising ECG signals using wavelet transform\n",
    "def denoise(data): \n",
    "    w = pywt.Wavelet('sym4')\n",
    "    maxlev = pywt.dwt_max_level(len(data), w.dec_len)\n",
    "    threshold = 0.04  # Threshold for filtering\n",
    "\n",
    "    coeffs = pywt.wavedec(data, 'sym4', level=maxlev)\n",
    "    for i in range(1, len(coeffs)):\n",
    "        coeffs[i] = pywt.threshold(coeffs[i], threshold * max(coeffs[i]))\n",
    "        \n",
    "    datarec = pywt.waverec(coeffs, 'sym4')\n",
    "    \n",
    "    return datarec\n",
    "\n",
    "# Function to add different types of noise to ECG signals\n",
    "def add_noise(data, noise_type=\"gaussian\", noise_level=0.01):\n",
    "    if noise_type == \"gaussian\":\n",
    "        noise = np.random.normal(0, noise_level, data.shape)\n",
    "    elif noise_type == \"salt_pepper\":\n",
    "        noise = np.random.choice([0, 1], size=data.shape, p=[1 - noise_level, noise_level])\n",
    "        noise = noise * (np.random.choice([-1, 1], size=data.shape))\n",
    "    elif noise_type == \"speckle\":\n",
    "        noise = data + data * np.random.normal(0, noise_level, data.shape)\n",
    "    elif noise_type == \"uniform\":\n",
    "        noise = np.random.uniform(-noise_level, noise_level, data.shape)\n",
    "    elif noise_type == \"exponential\":\n",
    "        noise = np.random.exponential(noise_level, data.shape)\n",
    "    else:\n",
    "        noise = np.zeros_like(data)\n",
    "    return data + noise\n",
    "\n",
    "# Path to MIT-BIH Arrhythmia Database\n",
    "path = '/kaggle/input/mitbit-arrhythmia-database/mitbih_database/'\n",
    "window_size = 1000  # Define the window size for segmenting ECG signals\n",
    "\n",
    "# Lists to store features (X)\n",
    "X = []\n",
    "\n",
    "# Read files from the dataset directory\n",
    "filenames = next(os.walk(path))[2]\n",
    "filenames.sort()\n",
    "\n",
    "# Segregate filenames and annotations\n",
    "records = []\n",
    "annotations = []\n",
    "for f in filenames:\n",
    "    filename, file_extension = os.path.splitext(f)\n",
    "    if file_extension == '.csv':\n",
    "        records.append(path + filename + file_extension)\n",
    "    else:\n",
    "        annotations.append(path + filename + file_extension)\n",
    "\n",
    "# Load data from records\n",
    "for r in range(0, len(records)):\n",
    "    signals = []\n",
    "\n",
    "    with open(records[r], 'rt') as csvfile:\n",
    "        spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        row_index = -1\n",
    "        for row in spamreader:\n",
    "            if row_index >= 0:\n",
    "                signals.insert(row_index, int(row[1]))\n",
    "            row_index += 1\n",
    "\n",
    "    signals = stats.zscore(signals)\n",
    "    \n",
    "    # Add noise to the signals\n",
    "    noisy_signals = add_noise(signals, noise_type=\"gaussian\", noise_level=0.05)\n",
    "    \n",
    "    # Denoise the noisy signals\n",
    "    denoised_signals = denoise(noisy_signals)\n",
    "    \n",
    "    # Store original, noisy, and denoised signals for evaluation\n",
    "    X.append((signals, noisy_signals, denoised_signals))\n",
    "\n",
    "# Visualize noise addition and removal\n",
    "plt.figure(figsize=(15, 18))\n",
    "\n",
    "# Testing and visualizing more signals\n",
    "num_signals_to_plot = min(5, len(X))  # Plot up to 5 signals or the number of available signals\n",
    "\n",
    "for i in range(num_signals_to_plot):\n",
    "    plt.subplot(num_signals_to_plot, 3, 3 * i + 1)\n",
    "    plt.plot(X[i][0][:3000])\n",
    "    if i == 0:\n",
    "        plt.title('Original Signal')\n",
    "\n",
    "    plt.subplot(num_signals_to_plot, 3, 3 * i + 2)\n",
    "    plt.plot(X[i][1][:3000])\n",
    "    if i == 0:\n",
    "        plt.title('Noisy Signal')\n",
    "\n",
    "    plt.subplot(num_signals_to_plot, 3, 3 * i + 3)\n",
    "    plt.plot(X[i][2][:3000])\n",
    "    if i == 0:\n",
    "        plt.title('Denoised Signal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the denoising performance\n",
    "original_signals = np.array([x[0] for x in X])\n",
    "noisy_signals = np.array([x[1] for x in X])\n",
    "denoised_signals = np.array([x[2] for x in X])\n",
    "\n",
    "mse_noisy = mean_squared_error(original_signals.flatten(), noisy_signals.flatten())\n",
    "mse_denoised = mean_squared_error(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "r2_noisy = r2_score(original_signals.flatten(), noisy_signals.flatten())\n",
    "r2_denoised = r2_score(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "mae_noisy = mean_absolute_error(original_signals.flatten(), noisy_signals.flatten())\n",
    "mae_denoised = mean_absolute_error(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "corr_noisy, _ = pearsonr(original_signals.flatten(), noisy_signals.flatten())\n",
    "corr_denoised, _ = pearsonr(original_signals.flatten(), denoised_signals.flatten())\n",
    "\n",
    "print(f'MSE (Noisy Signals): {mse_noisy}')\n",
    "print(f'MSE (Denoised Signals): {mse_denoised}')\n",
    "print(f'R^2 (Noisy Signals): {r2_noisy}')\n",
    "print(f'R^2 (Denoised Signals): {r2_denoised}')\n",
    "print(f'MAE (Noisy Signals): {mae_noisy}')\n",
    "print(f'MAE (Denoised Signals): {mae_denoised}')\n",
    "print(f'Correlation (Noisy Signals): {corr_noisy}')\n",
    "print(f'Correlation (Denoised Signals): {corr_denoised}')\n",
    "\n",
    "# Create DataFrame for evaluation metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['MSE', 'R2', 'MAE', 'Correlation'],\n",
    "    'Noisy': [mse_noisy, r2_noisy, mae_noisy, corr_noisy],\n",
    "    'Denoised': [mse_denoised, r2_denoised, mae_denoised, corr_denoised]\n",
    "})\n",
    "\n",
    "# Plot comparison of evaluation metrics\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(15, 10))\n",
    "for i, (idx, row) in enumerate(metrics_df.iterrows()):\n",
    "    ax = axes[i // 2, i % 2]\n",
    "    ax.bar(['Noisy', 'Denoised'], row[['Noisy', 'Denoised']], color=['red', 'green'])\n",
    "    ax.set_title(row['Metric'])\n",
    "    ax.set_ylabel(row['Metric'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot dataset distribution\n",
    "signal_lengths = [len(x[0]) for x in X]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(signal_lengths, bins=50, color='blue', edgecolor='black')\n",
    "plt.title('Distribution of Signal Lengths in the Dataset')\n",
    "plt.xlabel('Signal Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Pie chart for dataset distribution\n",
    "labels = ['Records', 'Annotations']\n",
    "sizes = [len(records), len(annotations)]\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140, colors=['skyblue', 'lightgreen'])\n",
    "plt.title('Distribution of Data Types in the Dataset')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-listening",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 52320,
     "sourceId": 97823,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30096,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 76.316604,
   "end_time": "2024-05-29T16:28:20.094326",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-29T16:27:03.777722",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
